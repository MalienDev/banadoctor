---
# Installation de Kafka avec Helm
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: kafka
  namespace: kafka
spec:
  repo: https://charts.bitnami.com/bitnami
  chart: kafka
  version: "22.1.0"
  targetNamespace: kafka
  createNamespace: true
  valuesContent: |-
    # Configuration de base
    image:
      registry: docker.io
      repository: bitnami/kafka
      tag: 3.4.0-debian-11-r0
      pullPolicy: IfNotPresent
    
    # Configuration des ressources globales
    resources:
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 500m
        memory: 1Gi
    
    # Configuration du nombre de répliques
    replicaCount: 3
    
    # Configuration de la persistance
    persistence:
      enabled: true
      size: 50Gi
      storageClass: "ssd"
      accessModes:
        - ReadWriteOnce
    
    # Configuration du stockage
    volumes:
      - name: data
        persistentVolumeClaim:
          accessModes:
            - ReadWriteOnce
          storageClassName: "ssd"
          resources:
            requests:
              storage: 50Gi
    
    # Configuration du service
    service:
      type: ClusterIP
      ports:
        client: 9092
        tls-client: 9093
        external: 9094
        jmx: 5555
    
    # Configuration de la sécurité
    auth:
      clientProtocol: sasl
      interBrokerProtocol: sasl
      sasl:
        enabled: true
        interBrokerMechanism: scram-sha-512
        clientUsers:
          - admin
        clientPasswords:
          - ${KAFKA_ADMIN_PASSWORD}
        zookeeperUser: admin
        zookeeperPassword: ${ZOOKEEPER_ADMIN_PASSWORD}
      tls:
        type: jks
        password: ${KAFKA_TLS_PASSWORD}
    
    # Configuration de la surveillance
    metrics:
      kafka:
        enabled: true
        serviceMonitor:
          enabled: true
          additionalLabels:
            release: kube-prometheus-stack
      jmx:
        enabled: true
    
    # Configuration des paramètres de Kafka
    config:
      # Paramètres de base
      broker.id: -1
      log.dirs: /bitnami/kafka/data
      log.retention.hours: 168
      log.segment.bytes: 1073741824
      log.retention.check.interval.ms: 300000
      zookeeper.connect: kafka-zookeeper:2181
      default.replication.factor: 3
      offsets.topic.replication.factor: 3
      transaction.state.log.replication.factor: 3
      transaction.state.log.min.isr: 2
      num.partitions: 3
      num.recovery.threads.per.data.dir: 1
      socket.send.buffer.bytes: 102400
      socket.receive.buffer.bytes: 102400
      socket.request.max.bytes: 104857600
      num.io.threads: 8
      num.network.threads: 3
      num.replica.fetchers: 2
      replica.fetch.min.bytes: 1
      replica.fetch.wait.max.ms: 500
      replica.socket.timeout.ms: 30000
      replica.socket.receive.buffer.bytes: 65536
      replica.lag.time.max.ms: 10000
      replica.high.watermark.checkpoint.interval.ms: 5000
      controller.socket.timeout.ms: 30000
      controller.message.queue.size: 10
      log.flush.interval.messages: 10000
      log.flush.interval.ms: 1000
      log.retention.check.interval.ms: 300000
      zookeeper.connection.timeout.ms: 6000
      zookeeper.session.timeout.ms: 6000
      zookeeper.sync.time.ms: 2000
      # Configuration SASL
      sasl.enabled.mechanisms: SCRAM-SHA-512
      sasl.mechanism.inter.broker.protocol: SCRAM-SHA-512
      security.inter.broker.protocol: SASL_PLAINTEXT
      # Configuration SSL
      ssl.client.auth: required
      ssl.keystore.type: JKS
      ssl.keystore.location: /opt/bitnami/kafka/config/certs/kafka.keystore.jks
      ssl.keystore.password: ${KAFKA_TLS_PASSWORD}
      ssl.key.password: ${KAFKA_TLS_PASSWORD}
      ssl.truststore.type: JKS
      ssl.truststore.location: /opt/bitnami/kafka/config/certs/kafka.truststore.jks
      ssl.truststore.password: ${KAFKA_TLS_PASSWORD}
      ssl.endpoint.identification.algorithm: 
      ssl.secure.random.implementation: SHA1PRNG
      ssl.client.auth: required
    
    # Configuration des tolérances
    tolerations:
      - key: "node-role.kubernetes.io/control-plane"
        operator: "Exists"
        effect: "NoSchedule"
    
    # Configuration des affinités
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                    - kafka
            topologyKey: "kubernetes.io/hostname"
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/arch
                  operator: In
                  values:
                    - amd64
                    - arm64
---
# Installation de Zookeeper avec Helm
apiVersion: helm.cattle.io/v1
kind: HelmChart
metadata:
  name: zookeeper
  namespace: kafka
spec:
  repo: https://charts.bitnami.com/bitnami
  chart: zookeeper
  version: "11.1.9"
  targetNamespace: kafka
  valuesContent: |-
    # Configuration de base
    image:
      registry: docker.io
      repository: bitnami/zookeeper
      tag: 3.8.1-debian-11-r0
      pullPolicy: IfNotPresent
    
    # Configuration des ressources
    resources:
      limits:
        cpu: 1
        memory: 1Gi
      requests:
        cpu: 500m
        memory: 512Mi
    
    # Configuration du nombre de répliques
    replicaCount: 3
    
    # Configuration de la persistance
    persistence:
      enabled: true
      size: 10Gi
      storageClass: "ssd"
    
    # Configuration de la sécurité
    auth:
      enabled: true
      clientUser: admin
      clientPassword: ${ZOOKEEPER_ADMIN_PASSWORD}
      serverUsers: admin
      serverPasswords: ${ZOOKEEPER_ADMIN_PASSWORD}
    
    # Configuration de la surveillance
    metrics:
      enabled: true
      serviceMonitor:
        enabled: true
        additionalLabels:
          release: kube-prometheus-stack
    
    # Configuration des tolérances
    tolerations:
      - key: "node-role.kubernetes.io/control-plane"
        operator: "Exists"
        effect: "NoSchedule"
    
    # Configuration des affinités
    affinity:
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                    - zookeeper
            topologyKey: "kubernetes.io/hostname"
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
            - matchExpressions:
                - key: kubernetes.io/arch
                  operator: In
                  values:
                    - amd64
                    - arm64
---
# Configuration des sujets Kafka
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: user-events
  namespace: kafka
  labels:
    strimzi.io/cluster: kafka
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 604800000  # 7 jours
    segment.bytes: 1073741824  # 1 Go
    cleanup.policy: delete
    compression.type: producer
---
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: notification-events
  namespace: kafka
  labels:
    strimzi.io/cluster: kafka
spec:
  partitions: 3
  replicas: 3
  config:
    retention.ms: 2592000000  # 30 jours
    segment.bytes: 1073741824  # 1 Go
    cleanup.policy: delete
    compression.type: producer
---
# Configuration de la politique réseau pour Kafka
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-kafka-traffic
  namespace: kafka
spec:
  description: "Allow traffic to Kafka"
  endpointSelector:
    matchLabels:
      app.kubernetes.io/name: kafka
  ingress:
  - fromEndpoints:
    - matchLabels:
        app.kubernetes.io/name: banadoctor-backend
    toPorts:
    - ports:
      - port: "9092"
        protocol: TCP
      - port: "9093"
        protocol: TCP
  egress:
  - toEndpoints:
    - matchLabels:
        app.kubernetes.io/name: zookeeper
    toPorts:
    - ports:
      - port: "2181"
        protocol: TCP
---
# Configuration de la politique réseau pour Zookeeper
apiVersion: cilium.io/v2
kind: CiliumNetworkPolicy
metadata:
  name: allow-zookeeper-traffic
  namespace: kafka
spec:
  description: "Allow traffic to Zookeeper"
  endpointSelector:
    matchLabels:
      app.kubernetes.io/name: zookeeper
  ingress:
  - fromEndpoints:
    - matchLabels:
        app.kubernetes.io/name: kafka
    toPorts:
    - ports:
      - port: "2181"
        protocol: TCP
  - fromEndpoints:
    - matchLabels:
        app.kubernetes.io/name: kafka
    toPorts:
    - ports:
      - port: "2888"
        protocol: TCP
      - port: "3888"
        protocol: TCP
  egress: []
